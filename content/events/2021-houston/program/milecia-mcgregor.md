+++
Talk_date = ""
Talk_start_time = ""
Talk_end_time = ""
Title = "Adding Reproducible Experiments To Your Machine Learning Pipeline"
Type = "talk"
Speakers = ["milecia-mcgregor"]
sharing_image = "milecia-mcgregor.png"

+++

It’s easy to lose track of which changes gave you the best result when you start exploring multiple model architectures. Tracking the changes in your hyperparameter values, along with code and data changes, will help you share results in different environments when you add these changes to your deploy pipeline.

In this talk, you will learn how you can use the open-source tool, DVC, to increase reproducibility for two methods of tuning hyperparameters: grid search and random search. We’ll go through a live demo of setting up and running grid search and random search experiments and pushing them through your CI/CD pipeline. By the end of the talk, you’ll know how to add reproducibility to your existing projects.
